{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Na dvojku\n",
    "# Definujeme hodnoty Z a jejich pravděpodobnosti P\n",
    "Z <- c(0, 1, 2, 3, 4, 5)\n",
    "P <- c(0.1, 0.2, 0.1, 0.3, 0.2, 0.1)\n",
    "\n",
    "# Výpočet střední hodnoty (μ)\n",
    "mu <- sum(Z * P)\n",
    "cat(\"Střední hodnota (μ):\", mu, \"\\n\")\n",
    "\n",
    "# Výpočet rozptylu (σ²) a směrodatné odchylky (σ)\n",
    "variance <- sum(P * (Z - mu)^2)\n",
    "std_dev <- sqrt(variance)\n",
    "cat(\"Rozptyl (σ²):\", variance, \"\\n\")\n",
    "cat(\"Směrodatná odchylka (σ):\", std_dev, \"\\n\")\n",
    "\n",
    "# Výpočet modu (nejčastější hodnota Z s nejvyšší pravděpodobností P)\n",
    "modus <- Z[which.max(P)]\n",
    "cat(\"Modus:\", modus, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Norm\n",
    "{r}\n",
    "x = 4 # hodnota pro kterou hledáme\n",
    "mu = 2 # střední hodnota rozdělení\n",
    "sigma = 3 # směrodatná odchylka tedy sigma^2\n",
    "\n",
    "print(glue(\"\n",
    "           P(X=x):  {dnorm(x, mean=mu, sd=sigma)} # Hustota\n",
    "           P(X<=x): {pnorm(x, mean=mu, sd=sigma)}\n",
    "           P(X<x):  {pnorm(x, mean=mu, sd=sigma)}  # DIST F\n",
    "           P(X>x):  {1-pnorm(x, mean=mu, sd=sigma)}\n",
    "           P(X>=x): {1-pnorm(x, mean=mu, sd=sigma)}\n",
    "           \n",
    "           Střední hodnota: {mu}\n",
    "           Rozptyl: {sigma*sigma}\n",
    "           Směrodatná odchylka: {sigma}\n",
    "           \"))\n",
    "\n",
    "q = 0.5 #pravděpodobnost pro kterou hledáme kvantil\n",
    "print(glue(\"\n",
    "\n",
    "           Kvantil P(X < x) = q: {qnorm(p, mean=mu, sd=sigma)} # NAŠE DEFINICE\n",
    "           \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "{r}\n",
    "# 1 Hustota\n",
    "x = seq(from = -5, to = 10, by = 0.01)\n",
    "f_x = dnorm(x, mean=mu, sd=sigma)\n",
    "plot(x, f_x, cex = 0.1)\n",
    "grid()\n",
    "\n",
    "# 2 Distribuční funkce\n",
    "F_x = pnorm(x, mean=mu, sd=sigma)\n",
    "plot(x, F_x, type=\"l\")\n",
    "grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'cpp11' is not available (for R version 3.6.1)\"\n",
      "Warning message:\n",
      "\"unable to access index for repository https://mirrors.nic.cz/R/bin/windows/contrib/3.6:\n",
      "  cannot open URL 'https://mirrors.nic.cz/R/bin/windows/contrib/3.6/PACKAGES'\"\n",
      "Warning message:\n",
      "\"dependencies 'cpp11', 'waldo' are not available\"\n",
      "also installing the dependencies 'pkgbuild', 'rprojroot', 'rex', 'brio', 'callr', 'cli', 'desc', 'digest', 'evaluate', 'jsonlite', 'lifecycle', 'magrittr', 'pkgload', 'praise', 'processx', 'ps', 'R6', 'rlang', 'covr', 'testthat'\n",
      "\n",
      "\n",
      "Warning message:\n",
      "\"unable to access index for repository https://mirrors.nic.cz/R/bin/windows/contrib/3.6:\n",
      "  cannot open URL 'https://mirrors.nic.cz/R/bin/windows/contrib/3.6/PACKAGES'\"\n",
      "Packages which are only available in source form, and may need\n",
      "  compilation of C/C++/Fortran: 'brio' 'cli' 'digest' 'jsonlite'\n",
      "  'magrittr' 'processx' 'ps' 'rlang' 'covr' 'testthat' 'readxl'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  These will not be installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "installing the source packages 'pkgbuild', 'rprojroot', 'rex', 'callr', 'desc', 'evaluate', 'lifecycle', 'pkgload', 'praise', 'R6'\n",
      "\n",
      "\n",
      "Warning message in install.packages(\"readxl\", dependencies = TRUE):\n",
      "\"installation of package 'lifecycle' had non-zero exit status\"\n",
      "Warning message in install.packages(\"readxl\", dependencies = TRUE):\n",
      "\"installation of package 'callr' had non-zero exit status\"\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "install.packages(\"readxl\")  # načtení xlsx souborů\n",
    "install.packages(\"moments\") # pro výpočet šikmosti a špičatosti\n",
    "install.packages(\"dplyr\")   # pro efektivní práci s datovým souborem\n",
    "install.packages(\"tidyr\")   # pro efektivní práci s datovým souborem (pivot_longer)\n",
    "install.packages(\"ggplot2\") # pro hezčí grafiku\n",
    "install.packages(\"ggpubr\")  # pro kombinování grafů z ggplot2\n",
    "install.packages(\"rstatix\") # pro identifikaci odlehlých pozorování\n",
    "install.packages(\"forcats\") # obsahuje funkci fct_infreq(), která seřadí úrovně faktorů podle četností\n",
    "install.packages(\"pacman\")  # Obsahuje příkaz p_load(), který zkontroluje\n",
    "install.packages(\"lawstat\") # Pro test symetrie\n",
    "install.packages(\"FSA\")     # Dunn test\n",
    "library(readxl)\n",
    "library(moments)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(ggplot2)\n",
    "library(ggpubr)\n",
    "library(rstatix)\n",
    "library(forcats)\n",
    "library(pacman)\n",
    "library(lawstat)\n",
    "library(FSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data = read_excel(\"C:\\\\Users\\\\BoushiPC\\\\Documents\\\\PythonScripts\\\\PS/data_20231220.xlsx\")\n",
    "colnames(data) = c(\n",
    "    \"Id\",\n",
    "    \"typ\",\n",
    "    \"zatepleni\",\n",
    "    \"spotreba2020\",\n",
    "    \"spotreba2022\"\n",
    ")\n",
    "data = as.data.frame(data)\n",
    "# Pokud by bylo treba filtrovat data podle sloupce\n",
    "data = data[ ,-c(1, 2)] # Vsechny sloupce krome prvniho a druheho\n",
    "head(dataS)\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data$increase = data$spotreba2020 - data$spotreba2022 # Tady to potom zalezi na nazvu sloupce, poradi taky zalezi, jestli resime pokles nebo rust\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "charakteristiky_dle_modelu = \n",
    "  data %>%\n",
    "  group_by(zatepleni) %>% # Tady je dulezite dat focus na group by, zalezi podle zadani, tady treba chteli se zamerit na zatepleni\n",
    "  summarise(rozsah = length(na.omit(increase)),\n",
    "            minimum = min(increase, na.rm=T),\n",
    "            Q1 = quantile(increase, 0.25, na.rm=T),\n",
    "            prumer = mean(increase, na.rm=T),\n",
    "            median = median(increase, na.rm=T),\n",
    "            Q3 = quantile(increase, 0.75, na.rm=T),\n",
    "            maximum = max(increase, na.rm=T),\n",
    "            rozptyl = var(increase, na.rm=T),\n",
    "            smerodatna_odchylka = sd(increase,na.rm=T),\n",
    "            variacni_koeficient = (100*(smerodatna_odchylka/prumer)),\n",
    "            sikmost = (moments::skewness(increase, na.rm=T)),\n",
    "            spicatost = (moments::kurtosis(increase, na.rm=T)-3),\n",
    "            dolni_mez = Q1 - 1.5 * (Q3 - Q1),\n",
    "            horni_mez = Q3 + 1.5 * (Q3 - Q1))\n",
    "t(charakteristiky_dle_modelu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Vzdycky tam to bude, ze budou dva nejake typy jak predtim amd a nvidia a bude se to porovnavat mezi sebou\n",
    "# Kdyby nahodou, tak tady jsou plots\n",
    "plot1 = ggplot(data, aes(x = fct_reorder(zatepleni,increase), y = increase))+ # Tady pozor na to zatepleni, increase, treba tam bude jiny sloupec nez zatepleni\n",
    "  stat_boxplot(geom = \"errorbar\", width = 0.2) +\n",
    "  geom_boxplot()+\n",
    "  labs(x = \"\", y = \"zvýšení výkonu od patche 1.5 (fps)\") +\n",
    "  theme_light()+\n",
    "  stat_summary(geom = \"point\", fun = \"mean\", colour = \"red\", size = 2, shape = 3) +\n",
    "  theme(plot.title = element_text(hjust = 0.5))\n",
    "plot1\n",
    "ggsave(\"plots/1.png\", plot1, width = 5, height = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Filtrace outlieru\n",
    "data$id = 1:length(data$zatepleni) # Pozor zatepleni\n",
    "outliers_increase = \n",
    "  data %>% \n",
    "  group_by(zatepleni) %>% # Pozor zatepleni\n",
    "  identify_outliers(increase)\n",
    "data$is_outlier <- data$id %in% outliers_increase$id\n",
    "data$id <- NULL\n",
    "data_outliers <- data[data$is_outlier == TRUE, ]\n",
    "data_outliers$is_outlier <- NULL\n",
    "data_outliers\n",
    "\n",
    "data_filtered <- data[data$is_outlier == FALSE, ]\n",
    "data_filtered$is_outlier <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "hist <- ggplot(data,\n",
    "                aes(x = increase)) +\n",
    "  geom_histogram(binwidth = 0.4,\n",
    "                 color = \"black\",    \n",
    "                 fill = \"lightblue\") + \n",
    "  geom_density() +\n",
    "  labs(x = \"zvýšení výkonu od patche 1.5 (fps)\", y = \"četnost\") +\n",
    "  theme_bw() +\n",
    "  theme(axis.text = element_text(color = \"black\", size = 13),\n",
    "        axis.title = element_text(size = 13),\n",
    "        plot.title = element_text(hjust = 0.5)) + \n",
    "  facet_wrap(~fct_reorder(zatepleni, increase), nrow = 2) # Pozor zatepleni\n",
    "qq <- ggplot(data, aes(sample = increase))+\n",
    "  stat_qq()+\n",
    "  stat_qq_line()+\n",
    "  theme_bw() +\n",
    "  labs(x = \"norm. teoretické kvantily\", y = \"výběrové kvantily\") +\n",
    "  facet_wrap(\"zatepleni\", nrow = 2, scales = \"free\") # Pozor zatepleni\n",
    "ggarrange(hist, qq, nrow = 1)\n",
    "ggsave(\"plots/2.png\", ggarrange(hist, qq, nrow = 1), width = 10, height = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# TAK TED ZACINAJI TY MAIN STEPS CO JE TREBA UDELAT VZDY, TOHLE PREDTIM JE JENOM PRIPRAVA DAT/GRAFY PRO PRIPAD\n",
    "# Nejdrive si data rozdelit na ty dve veci ktere budu spolu porovnavat\n",
    "data_First <- subset(data, zatepleni == \"ano\")$increase # Pozor zatepleni u obou\n",
    "data_Second <- subset(data, zatepleni == \"ne\")$increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Nejprve je třeba udělat test o normalnim rozdeleni, pokud je hodnota mensi nez 0.05, pak neni z normalniho rozdeleni\n",
    "shapiro.test(data_First)$p.value\n",
    "shapiro.test(data_Second)$p.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Pokud nejake z nich neni z normalniho rozdeleni, pak je treba udelat test symetrie\n",
    "symmetry.test(data_First, boot = FALSE)$p.value\n",
    "symmetry.test(data_Second, boot = FALSE)$p.value\n",
    "# Pokud obe vyjdou symetricka -> vetsi nez 0.05, pak postupujeme s nimi aspon jako se symetrickyma (pokud nevysly normalni), pokud jedno nevyjde symetricke, pak s nimi postupujeme jako s nesym a nenorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# BODOVY ODHAD\n",
    "# Pokud mame normalni data, pak pouzivame prumer, pokud mame jenom symetricke, tak pouzivame median\n",
    "mean(data_First)\n",
    "mean(data_Second)\n",
    "# Nebo\n",
    "median(data_First)\n",
    "median(data_Second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Jestlize jsou normalni \n",
    "t.test(data_First, mu = 0, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95) # two.sided, less, greater -> levostranný = greater\n",
    "t.test(data_Second, mu = 0, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95)\n",
    "# Jestlize nejsou normalni\n",
    "wilcox.test(data_First, mu = 0, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95)\n",
    "wilcox.test(data_Second, mu = 0, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ukazka popisu \n",
    "U výrobce A lze očekávat, že polovina akumulátorů bude vykazovat pokles kapacity menší než cca  \n",
    "196,2 mAh. 95% levostranný intervalový odhad mediánu poklesu kapacit u výrobce A je  \n",
    "(190,4; +∞) mAh. Intervalový odhad, stejně jako p-hodnota Wilcoxonova testu, ukazují, že medián  \n",
    "poklesu kapacit je statisticky významně větší než nula. Tj. na hladině významnosti 0,05 lze pokles  \n",
    "kapacity akumulátorů výrobce A považovat za statisticky významný. Odhady pro výrobce B lze  \n",
    "interpretovat obdobně (viz Tab. 3).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Ted overime jestli se statisticky vyznamne lisi nebo ne, predpoklad je ze zase budeme mit 2 ruzne\n",
    "# Nejprve si udelame podil tech dvou\n",
    "var_First <- var(data_First)\n",
    "var_Second <- var(data_Second)\n",
    "var_Second / var_First\n",
    "# Pokud to cislo vyjde x >= 2, pak jsou odlisne, tohle je jenom parametricka kontrola tho, jeste se bude delat test\n",
    "# Pak se udela F-test pro overeni variance x >= 0.05 znamena ze jsou stejne \n",
    "var.test(data_First, data_Second)\n",
    "# Rozdil medianu -> Bodovy odhad\n",
    "print(mean(data_First, na.rm=T) - mean(data_Second, na.rm=T)) # Pro normalni\n",
    "print(median(data_First, na.rm=T) - median(data_Second, na.rm=T))\n",
    "# Čisté Testy\n",
    "wilcox.test(data_First, data_Second, mu = 0, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95) # Pro nenormalni data, dat si pozor na konkretni conf level a alternative\n",
    "\n",
    "\n",
    "#POZOR U T-TESTU POKUD JSI MEL ROZDINLE VARIANCE VIZ F TEST A POMERY MUSIS DODAT var.equal = FALSE \n",
    "t.test(data_First, data_Second, mu = 0, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95, var.equal = FALSE) # Pro normalni data\n",
    "\n",
    "# Pokud je x < 0.05, tak se lisi a ten rozdil je statisticky vyznamny (to x, hladina vyznamnosti muze byt jina hodnota nez 5%)\n",
    "\n",
    "# Pokud se mě ptaji na porovnani s nějakou konstantou, pak se daji data (treba zateplene) a druhy parametr je ta konstanta\n",
    "wilcox.test(data_First , mu = 1000, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95) # Overit si ktere data chteji porovnat (data_First nebo data_Second)\n",
    "\n",
    "# Sign test\n",
    "sign_test_result <- SIGN.test(data_First, md = 8625*0.1, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Další kroky\n",
    "Teď nastanou dvě možné scénáře, buď budu analyzovat několik druhů dat najednou -> vícevýběrový test  \n",
    "Nebo budu dělat různou analýzu což je celkem cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Vícevýběrové testy\n",
    "data = read_excel(\"C:\\\\Users\\\\BoushiPC\\\\Documents\\\\PythonScripts\\\\PS/data_20231220.xlsx\")\n",
    "colnames(data) = c(\n",
    "    \"Id\",\n",
    "    \"typ\",\n",
    "    \"zatepleni\",\n",
    "    \"spotreba2020\",\n",
    "    \"spotreba2022\"\n",
    ")\n",
    "data = as.data.frame(data)\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data$increase = data$spotreba2020 - data$spotreba2022\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Filtrace outlieru\n",
    "data$id = 1:length(data$typ) # Pozor zatepleni\n",
    "outliers_increase = \n",
    "  data %>% \n",
    "  group_by(typ) %>% # Pozor zatepleni\n",
    "  identify_outliers(increase)\n",
    "data$is_outlier <- data$id %in% outliers_increase$id\n",
    "data$id <- NULL\n",
    "data_outliers <- data[data$is_outlier == TRUE, ]\n",
    "data_outliers$is_outlier <- NULL\n",
    "data_outliers\n",
    "\n",
    "data_filtered <- data[data$is_outlier == FALSE, ]\n",
    "data_filtered$is_outlier <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data_First <- subset(data_filtered, typ == \"elektricke\")$increase\n",
    "data_Second <- subset(data_filtered, typ == \"plynove\")$increase\n",
    "data_Third <- subset(data_filtered, typ == \"tuha_paliva\")$increase\n",
    "data_Fourth <- subset(data_filtered, typ == \"tepelne_cerpadlo\")$increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# TEST NORMALITY\n",
    "#Tohle byla priprava dat a ted jeste overim predpoklady\n",
    "shapiro.test(data_First)$p.value\n",
    "shapiro.test(data_Second)$p.value\n",
    "shapiro.test(data_Third)$p.value\n",
    "shapiro.test(data_Fourth)$p.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# TEST SYMETRIE\n",
    "#Pokud nebudou normalni tak jeste test symetrosti\n",
    "symmetry.test(data_First, boot = FALSE)$p.value\n",
    "symmetry.test(data_Second, boot = FALSE)$p.value\n",
    "symmetry.test(data_Third, boot = FALSE)$p.value\n",
    "symmetry.test(data_Fourth, boot = FALSE)$p.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "var_First <- var(data_First)\n",
    "var_Second <- var(data_Second)\n",
    "var_Third <- var(data_Third)\n",
    "var_Fourth <- var(data_Fourth)\n",
    "cat(\"Rozptyl pro model 1:\", var_First, \"\\n\")\n",
    "cat(\"Rozptyl pro model 2:\", var_Second, \"\\n\")\n",
    "cat(\"Rozptyl pro model 3:\", var_Third, \"\\n\")\n",
    "cat(\"Rozptyl pro model 4:\", var_Fourth, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Checknout jestli jsou statisticky vyznamne odlisne, bude zalezet na zadani ktere sloupce budeme porovnavat\n",
    "var_First / var_Second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "all_values <- c(data_First, data_Second, data_Third, data_Fourth)\n",
    "groups <- factor(c(rep(\"1\", length(data_First)), \n",
    "                   rep(\"2\", length(data_Second)), \n",
    "                   rep(\"3\", length(data_Third)), \n",
    "                   rep(\"4\", length(data_Fourth))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# SHODA ROZPTYLU -> HOMOGENNI DATA\n",
    "# Checkne variance cele groupy mezi sebou -> jestli jsou homogenni -> jestli je x < 0.05 tak nejsou shodne. Takže zamitame předpoklad o shodě rozptylu\n",
    "bartlett_result <- bartlett.test(all_values ~ groups)\n",
    "print(bartlett_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# INTERVALOVE A BODOVE ODHADY\n",
    "# Ted pro intervalove a bodove odhady je treba jak normalita vsech tak symetricnost vsech, pouze tehdy pouzijeme prumer, jinak pouzijeme median\n",
    "median(data_First)\n",
    "median(data_Second)\n",
    "median(data_Third)\n",
    "median(data_Fourth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# INTERVALOVE A BODOVE ODHADY\n",
    "# Opet, pokud splnuji vsechny jak normalitu tak symetricnost, tak provedeme t-test, jinak wilcox a median\n",
    "t.test(data_First, mu = 0, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95)\n",
    "t.test(data_Second, mu = 0, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95)\n",
    "t.test(data_Third, mu = 0, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95)\n",
    "t.test(data_Fourth, mu = 0, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95)\n",
    "# Pokud nesplnuji normalitu nebo symetrii\n",
    "wilcox.test(data_First, mu = 0, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95)\n",
    "wilcox.test(data_Second, mu = 0, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95)\n",
    "wilcox.test(data_Third, mu = 0, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95)\n",
    "wilcox.test(data_Fourth, mu = 0, alternative = \"greater\", conf.int = TRUE, conf.level = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "combined_data <- data.frame(\n",
    "  values = c(data_First, data_Second, data_Third, data_Fourth),\n",
    "  group = factor(c(rep(\"1\", length(data_First)), \n",
    "                   rep(\"2\", length(data_Second)), \n",
    "                   rep(\"3\", length(data_Third)), \n",
    "                   rep(\"4\", length(data_Fourth))))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# OPET TESTUJEME ZDA-LI SE LISI ALE TESTUJEME TO PRO VSECHNY DOHROMADY + POST-HOC ANALYZA\n",
    "# TADY ZASE, POKUD BYLY SHODNE ROZPTYLY + NORMALITA DAT -> ANOVA + Tukyho test, POKUD NE -> Kruskalův-Wallisův test + Dunnové test\n",
    "# Anova + Tuky\n",
    "anova_test <- aov(values ~ group, data = combined_data)\n",
    "summary(anova_test)\n",
    "TukeyHSD(anova_test)\n",
    "# Kruskal + Dunn\n",
    "# Podle Z muzeme videt co je vetsi a co je mensi (1st data - 2nd data např)\n",
    "# Podle p.adj mužeme rozhodnout jestli mají x < 0.05, pak se jejich mediany statisticky vyznamně liší \n",
    "kruskal_test <- kruskal.test(values ~ group, data = combined_data)\n",
    "print(kruskal_test)\n",
    "dunn_test <- dunnTest(values ~ group, data = combined_data, method = \"bonferroni\")\n",
    "dunn_test$res\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
